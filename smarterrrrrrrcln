#!/usr/bin/env python3
import os
import argparse
import fnmatch
import datetime


def get_size(path):
    """Return size of file or directory in bytes."""
    total_size = 0
    if os.path.isfile(path):
        return os.path.getsize(path)
    for dirpath, _, filenames in os.walk(path):
        for f in filenames:
            fp = os.path.join(dirpath, f)
            try:
                total_size += os.path.getsize(fp)
            except OSError:
                pass
    return total_size


def scan_large_items(target_dir, threshold_mb):
    """Scan recursively for files and directories over threshold MB."""
    threshold_bytes = threshold_mb * 1024 * 1024
    large_items = []

    for root, dirs, files in os.walk(target_dir):
        # Check files
        for f in files:
            path = os.path.join(root, f)
            try:
                if os.path.getsize(path) >= threshold_bytes:
                    large_items.append(path)
            except OSError:
                pass

        # Check dirs (size of contents)
        for d in dirs:
            path = os.path.join(root, d)
            size = get_size(path)
            if size >= threshold_bytes:
                large_items.append(path)

    return large_items


def load_list(file_path: str):
    """Load lines from a text file into a set (skip blanks/comments)."""
    if not os.path.exists(file_path):
        print(f"[WARN] File '{file_path}' not found.")
        return set()
    with open(file_path, "r") as f:
        return {line.strip() for line in f if line.strip() and not line.startswith("#")}


def filter_deletable_files(found_files, approved_patterns):
    """Return only files that match an approved absolute path or wildcard pattern."""
    deletable = []
    for f in found_files:
        for pattern in approved_patterns:
            if fnmatch.fnmatch(f, pattern):  # full path wildcard match
                deletable.append(f)
                break
    return deletable


def cleanup_old_files(base_dir, days, do_delete):
    """Remove files older than N days inside base_dir."""
    cutoff = datetime.datetime.now() - datetime.timedelta(days=days)
    deleted = []

    if not os.path.exists(base_dir):
        return deleted

    for root, _, files in os.walk(base_dir):
        for fname in files:
            path = os.path.join(root, fname)
            try:
                mtime = datetime.datetime.fromtimestamp(os.path.getmtime(path))
                if mtime < cutoff:
                    deleted.append(path)
                    if do_delete:
                        os.remove(path)
            except Exception as e:
                print(f"[ERROR] Could not process {path}: {e}")
    return deleted


def main():
    parser = argparse.ArgumentParser(description="Unified disk cleanup script")
    parser.add_argument("target_dir", help="Target directory to scan recursively")
    parser.add_argument("--approved-list", required=True,
                        help="File containing approved file paths or wildcard patterns (absolute paths)")
    parser.add_argument("--threshold", type=int, default=500,
                        help="Size threshold in MB (default: 500)")
    parser.add_argument("--retention", type=int, default=7,
                        help="Delete files older than N days in log/ and report/ (default: 7)")
    parser.add_argument("--delete", action="store_true",
                        help="Actually delete files instead of dry run")
    args = parser.parse_args()

    # --- Large files/dirs ---
    print(f"\n[INFO] Scanning '{args.target_dir}' for items over {args.threshold}MB...")
    found_items = scan_large_items(args.target_dir, args.threshold)
    if found_items:
        print(f"[INFO] Found {len(found_items)} large files/directories:")
        for item in found_items:
            size_mb = get_size(item) / (1024 * 1024)
            print(f"  {item} ({size_mb:.1f} MB)")
    else:
        print("[INFO] No large files or directories found.")

    approved_patterns = load_list(args.approved_list)
    deletable_items = filter_deletable_files(found_items, approved_patterns)

    if deletable_items:
        print("\n[INFO] Items eligible for deletion (approved list matched):")
        for f in deletable_items:
            print(f"  {f}")

        if args.delete:
            print("\n[INFO] Deleting approved large items...")
            for f in deletable_items:
                try:
                    if os.path.isfile(f):
                        os.remove(f)
                    elif os.path.isdir(f):
                        # remove entire directory tree
                        import shutil
                        shutil.rmtree(f)
                    print(f"[DELETED] {f}")
                except Exception as e:
                    print(f"[ERROR] Could not delete {f}: {e}")
        else:
            print("\n[INFO] Dry run: No large items deleted.")
    else:
        print("\n[INFO] No large items matched approved list.")

    # --- Retention cleanup (log + report) ---
    osi_env = os.environ.get("OSI")
    if osi_env:
        print(f"\n[INFO] Running retention cleanup (older than {args.retention} days)...")
        for subdir in ["log", "report"]:
            base_dir = os.path.join(osi_env, subdir)
            old_files = cleanup_old_files(base_dir, args.retention, args.delete)
            if old_files:
                print(f"\n[INFO] Files in {base_dir} eligible for deletion (>{args.retention} days old):")
                for f in old_files:
                    print(f"  {f}")
                if args.delete:
                    print(f"[INFO] Deleted {len(old_files)} files from {base_dir}")
                else:
                    print(f"[INFO] Dry run: {len(old_files)} old files listed, none deleted.")
            else:
                print(f"[INFO] No old files found in {base_dir}")
    else:
        print("\n[WARN] OSI environment variable not set, skipping log/report cleanup.")


if __name__ == "__main__":
    main()